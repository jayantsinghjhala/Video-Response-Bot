# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tHPyegnAP17_LmPEFPtgvN_9SSjM2gWF
"""

import os
import uuid
import openai
import psutil
from dotenv import load_dotenv

load_dotenv()
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# Initialize the OpenAI client
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def generate_unique_filename(directory, extension):
    unique_filename = f"{uuid.uuid4()}{extension}"
    return os.path.join(directory, unique_filename)


def clean_directory(directory):
    for filename in os.listdir(directory):
        file_path = os.path.join(directory, filename)
        try:
            if os.path.isfile(file_path) or os.path.islink(file_path):
                # Check if the file is in use
                for proc in psutil.process_iter(['open_files', 'name']):
                    try:
                        for open_file in proc.open_files():
                            if open_file.path == file_path:
                                print(f"File {file_path} is in use by {proc.name()}, skipping.")
                                break
                        else:
                            continue
                        break
                    except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                        continue
                else:
                    os.unlink(file_path)
                    print(f"Deleted {file_path}")
        except Exception as e:
            print(f'Failed to delete {file_path}. Reason: {e}')

# Define the function to generate AI responses
def generate_response(PROMPT, MaxToken=150, outputs=1):
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": "Answer this question as if you are President Joe Biden, in less than 70 words",
            },
            {"role": "user", "content": PROMPT},
        ],
        max_tokens=MaxToken,
        n=outputs,
    )
    # output = [choice.message.content.strip() for choice in response.choices]
    return response.choices[0].message.content.strip()


import time
from openai import OpenAIError


def text_to_speech(text, voice="onyx"):
    try:
        client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        response = client.audio.speech.create(
            model="tts-1",
            voice=voice,
            input=text
        )

        audio_directory = os.path.join(BASE_DIR, "audio")
        clean_directory(audio_directory)
        output_path = generate_unique_filename(audio_directory, ".mp3")

        # Write the response content to the file
        with open(output_path, 'wb') as audio_file:
            for chunk in response.iter_bytes():
                audio_file.write(chunk)

        print(f"Audio file saved as {output_path}")
        return output_path

    except OpenAIError as e:
        print(f"OpenAI API error: {e}")
        return None
    except Exception as e:
        print(f"Unexpected error in text_to_speech: {e}")
        return None


import os
import requests
import json
import urllib.request
from time import sleep


def lipsync_request(video_path, audio_path, api_key):
    files = [
        ("input_face", open(video_path, "rb")),
        ("input_audio", open(audio_path, "rb")),
    ]
    payload = {
        "functions": None,
        "variables": None,
        "face_padding_top": 0,
        "face_padding_bottom": 18,
        "face_padding_left": 0,
        "face_padding_right": 0,
        "sadtalker_settings": None,
        "selected_model": "Wav2Lip",
    }
    response = requests.post(
        "https://api.gooey.ai/v3/Lipsync/async/form/",
        headers={"Authorization": f"Bearer {api_key}"},
        files=files,
        data={"json": json.dumps(payload)},
    )
    response.raise_for_status()
    status_url = response.headers["Location"]

    while True:
        response = requests.get(
            status_url, headers={"Authorization": f"Bearer {api_key}"}
        )
        response.raise_for_status()
        result = response.json()
        if result["status"] in ["completed", "failed"]:
            return result
        sleep(3)


def download_video(result):
    if result["status"] == "completed":
        video_url = result["output"]["output_video"]
        output_directory = os.path.join(BASE_DIR, "output")
        clean_directory(output_directory)
        output_path = generate_unique_filename(output_directory, ".mp4")

        urllib.request.urlretrieve(video_url, output_path)
        print(f"Video downloaded as {output_path}")
        return output_path
    else:
        print("Lipsync job failed")
        return None

# question="how you plan to tackle the drug situation in certain parts of america if you are elected again as president of united states in next elections?"
# ai_ans=generate_response(question)
# # print(ai_ans)
# text_to_speech(ai_ans)


# video_path="video/moving_3gp_144_use.mp4"
# audio_path="audio/output.mp3"
# job_response = lipsync_request(video_path,audio_path,api_key_gooey)
# download_video(job_response)


import sys
import psutil
import nest_asyncio
import asyncio
from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)
from telegram.error import TimedOut, TelegramError

nest_asyncio.apply()


def get_script_name():
    try:
        return os.path.basename(__file__)
    except NameError:
        return "model.py"  # or any other default name


def terminate_previous_instances(script_name):
    current_process = psutil.Process(os.getpid())
    for proc in psutil.process_iter(["pid", "name", "cmdline"]):
        if proc.info["pid"] == current_process.pid:
            continue
        if (
            proc.info["name"] == current_process.name()
            and "python" in proc.info["cmdline"][0]
        ):
            if len(proc.info["cmdline"]) > 1 and proc.info["cmdline"][1].endswith(
                script_name
            ):
                proc.terminate()
                proc.wait()


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text(
        "Hello! Now Mr. President will answer your questions."
    )


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text('Please Wait! Mr. President is Thinking.')
    question = update.message.text
    ai_ans = generate_response(question)
    
    audio_path = text_to_speech(ai_ans)
    if audio_path is None:
        await update.message.reply_text('I apologize, but there was an issue generating the speech. Please try again later.')
        return

    api_key_gooey = os.getenv("GOOEY_API_KEY")

    video_path = os.path.join(BASE_DIR, "raw_vid", "moving_3gp_144_use.mp4")
    
    if not os.path.exists(video_path):
        print(f"Video file not found: {video_path}")
        await update.message.reply_text('Interview Terminated! Mr. President is not Available Anymore.')
        return

    if not os.path.exists(audio_path):
        print(f"Audio file not found: {audio_path}")
        await update.message.reply_text('Interview Terminated! Mr. President is not Available Anymore.')
        return
    
    job_response = lipsync_request(video_path, audio_path, api_key_gooey)
    output_video_path = download_video(job_response)

    if output_video_path and os.path.exists(output_video_path):
        max_retries = 3
        for attempt in range(max_retries):
            try:
                with open(output_video_path, 'rb') as video_file:
                    await update.message.reply_video(video=video_file)
                break
            except TimedOut:
                if attempt < max_retries - 1:
                    await asyncio.sleep(5)  # Wait for 5 seconds before retrying
                else:
                    await update.message.reply_text('I apologize, but there was an issue sending the video. Please try again later.')
            except TelegramError as e:
                await update.message.reply_text(f'An error occurred: {str(e)}')
                break
    else:
        await update.message.reply_text('I apologize, but there was an issue generating the video. Please try again later.')

    # No need to manually delete files here, as they will be cleaned up in the next run

async def main() -> None:
    app = ApplicationBuilder().token(os.getenv("TELEGRAM_BOT_TOKEN")).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    await app.run_polling()


if __name__ == "__main__":
    script_name = get_script_name()
    terminate_previous_instances(script_name)
    try:
        asyncio.run(main())
    except RuntimeError:
        # If we're in an environment that already has a running event loop
        loop = asyncio.get_event_loop()
        loop.create_task(main())
